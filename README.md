# ğŸ“š PDF Question Answering App using RAG and Chainlit

A seamless PDF Question Answering application using Retrieval-Augmented Generation (RAG) with an interactive Chainlit frontend. Upload a PDF, get it processed and chunked, generate vector embeddings, store in **Pinecone**, and get instant answers to your queriesâ€”powered by cutting-edge NLP tools.

---

## ğŸ”§ Tech Stack

- **LangChain** â€“ Document loading, smart text splitting, and chaining.
- **PyMuPDF (`fitz`)** â€“ Robust PDF parsing and extraction.
- **SentenceTransformers (GTE-Large)** â€“ High-quality embedding generation.
- **Pinecone** â€“ Fast and scalable vector database for similarity search.
- **Cohere Re-rank** â€“ Enhanced context selection for better accuracy.
- **Google Gemini 2.0 Flash** â€“ Advanced LLM for answering queries.
- **Chainlit** â€“ Interactive, real-time chat frontend.

---

## âš™ï¸ Features

- ğŸ“„ Upload PDFs up to 40MB
- ğŸ” Intelligent text chunking and vector embedding
- ğŸš€ Lightning-fast vector search and retrieval (Pinecone)
- ğŸ” Context reranking with Cohere for precise answers
- ğŸ’¬ Natural language Q&A using Gemini 2.0 Flash
- âœ… Duplicate embedding avoidance with PDF hashing
- ğŸ§  Streamed, real-time answer typing for great UX

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Dhananjay-prod/RAG.git
cd RAG
```

### 2. Create a Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
# Or, if using Conda:
# conda create -n pdf-rag-chainlit python=3.10
# conda activate pdf-rag-chainlit
```

### 3. Install Dependencies

Make sure you have a `requirements.txt` file listing all dependencies. Example content:

```
langchain-community
pymupdf
pinecone-client
sentence-transformers
tqdm
chainlit
cohere
google-generativeai
requests
```

Install all dependencies at once:

```bash
pip install -r requirements.txt
```

> **Tip:** It's best to keep your requirements.txt up-to-date as you add/remove libraries!

### 4. Set Your API Keys

Be sure to set your API keys securely (e.g., using environment variables or a `.env` file). **Never hardcode secrets in your code!**

Example in your Python code (using environment variables):

```python
import os
COHERE_API_KEY = os.getenv("COHERE_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
import google.generativeai as genai
client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
```

Or, if using a `.env` file, consider [python-dotenv](https://pypi.org/project/python-dotenv/) for automatic loading.

### 5. Run the App

```bash
chainlit run app.py
```

---

## ğŸ“‚ File Structure

```
ğŸ“ RAG/
â”œâ”€â”€ app.py               # Main Chainlit app
â”œâ”€â”€ requirements.txt     # Required dependencies
â”œâ”€â”€ README.md            # Project documentation
```

---

## ğŸ“ Notes & Best Practices

- **API Keys**: Store keys securely! Use environment variables or a `.env` file, not plain text in code.
- **requirements.txt**: Keep this in sync with your imports for reproducibility.
- **PDF size**: The app currently accepts PDFs up to 40MB (adjust as needed).
- **Extensibility**: The codebase is modular, so feel free to swap out the LLM or vector DB as needed.

---

## ğŸ™ Acknowledgements

- [LangChain](https://github.com/langchain-ai/langchain)
- [SentenceTransformers](https://www.sbert.net/)
- [Pinecone](https://www.pinecone.io/)
- [Cohere](https://cohere.com/)
- [Google Generative AI](https://ai.google.dev/)
- [Chainlit](https://www.chainlit.io/)

---

## ğŸ“¬ License

MIT License

---

Feel free to open issues or pull requests to contribute or ask questions!
